{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The preceding notebook shows how a risk manager can characterize the risk of a portfolio using a frequency distribution. This process uses the tools of probability, a mathematical abstraction that constructs the distribution of random variable. These random variables are financial risk factors, such as movements in stock prices, in bond prices, in exchange rates, and in commodity prices. These risk factor are then transformed into profits and losses on the portfolio, which can be described by a probability distribution function.\n",
    "\n",
    "Table of contents:\n",
    "- [Characterize Random Variables](#characterize_random_variables)\n",
    "- [Multivariate Distribution Functions](#multivariate_distribution_functions)\n",
    "- [Functions of Random Variables](#functions_of_random_variables)\n",
    "- [Important Distribution Functions](#important_distribution_functions)\n",
    "- [Distribution_of_Averages](#distribution_of_averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"characterize_random_variables\">Characterize Random Variables</a>\n",
    "The classical approach to probability is based on the concept of the **random variable ($RV$)**. This can be viewed as the outcome from throwing a die. Each realization is generated from a fixed process. If the die is perfectly symmetrical, with six-faces, we could say that the probability of observing a face with a specified number in one throw is $p = 1/6$.\n",
    "### Univariate distribution functions\n",
    "For example, a random variable $X$ is characterized by a **distribution function**, \n",
    "\n",
    "$F(x) = P(X \\leq x)$\n",
    "\n",
    "which is the probability that the realization of the random variable $X$ ends up less than or equal to the given number $x$. This is also called a **cumulative distribution function**.\n",
    "\n",
    "When the variable $X$ takes discrete values, this distribution is obtained by summing the step values less than or equal to $x$. That is\n",
    "\n",
    "$F(x) = \\Sigma_{x_{j} \\leq x}f(x_{j})$\n",
    "\n",
    "where the function $f(x)$ is called the **frequency function** or the **probability density function ($p.d.f$)**.\n",
    "\n",
    "When the variable is continuous, the distribution is given by \n",
    "\n",
    "$F(x) = \\int^{x}_{-\\infty}f(u)du$\n",
    "\n",
    "The density can be obtained from the distribution using \n",
    "\n",
    "$f(x) = \\frac{dF(x)}{dx}$\n",
    "\n",
    "Often, the random variable will be described interchangeably by its distribution or its density.\n",
    "\n",
    "The density $f(u)$ must be positive for all $u$. As $x$ tends to infinity, the distribution tends to unity as it represents the total probability of any draw for $x$:\n",
    "\n",
    "$\\int^{\\infty}_{-\\infty}f(u)du = 1$\n",
    "\n",
    "### Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random variable is characterized by its distribution function. We can summarize it by a few parameters, or **moments**.\n",
    "\n",
    "For instance, the expected value for $x$, or **mean**, is given by the integral \n",
    "\n",
    "$\\mu = E(X) = \\int^{+\\infty}_{-\\infty}xf(x)dx$\n",
    "\n",
    "which measures the central tendency, or center of gravity of the population.\n",
    "\n",
    "The distribtion can also be described by its **quantile**, which is the cutoff point $x$ with an associated probability $c$:\n",
    "\n",
    "$F(x) = \\int^{x}_{-\\infty}f(u)du$ = c\n",
    "\n",
    "Define this quantile as $Q(X, c)$. The $50%$ quantile is known as the **median**.\n",
    "\n",
    "In fact, value at risk ($VAR$) can be interpreted as the cutoff point such that a loss will not happen with probability greater than $p = 95%$. If $f(u)$ us the distribution of profit and losses on the portfolio, $VAR$ is defined from \n",
    "\n",
    "$F(x) = \\int^{x}_{-\\infty}f(u)du = (1 - p)$\n",
    "\n",
    "where $p$ is the right-tail probability, and $c$ the usual left-tail probability. $VAR$ can be defined as minus the quantile itself, or alternatively, the deviation between the expected value and the quantile, \n",
    "\n",
    "$VAR(c) = E(X) - Q(X, c)$\n",
    "\n",
    "Note that $VAR$ is typically reported as a loss (i.e., a positive number), which explains the negative sign.\n",
    "\n",
    "Another useful moment is the squared dispersion around the mean, or **variance**:\n",
    "\n",
    "$\\sigma^{2} = V(X) = \\int^{+\\infty}_{-\\infty}[x - E(X)]^{2}f(x)dx$\n",
    "\n",
    "The **standard deviation** is more convenient to use as it has the same units as the original variable $X$:\n",
    "\n",
    "$SD(X) = \\sigma = \\sqrt{V(X)}$\n",
    "\n",
    "The scaled third moment is the **skewness**, which describes departures from symmetry. It is defined as\n",
    "\n",
    "$\\gamma = (\\int^{+\\infty}_{-\\infty}[x - E(X)]^{3}f(x)dx)/\\sigma^{3}$\n",
    "\n",
    "Negative skewness indicates that the distribution has a long left tail, which indicates a high probability of observing large negative values. If this represents the distribution of profits and losses for a portfolio, this is a dangerous situation.\n",
    "\n",
    "The scaled fourth moment is the **kurtosis**, which describes the degree of flatness of a distribution, or width of its tails. It is defined as \n",
    "\n",
    "$\\delta = (\\int^{+\\infty}_{-\\infty}[x - E(X)]^{4}f(x)dx)/\\sigma^{4}$\n",
    "\n",
    "Because of the fourth power, large observations in the tail will have a large weight and hence create large kurtosis. Such a distribution is called **leptokurtic**, or **fat-tailed**. This parameter is very important for risk management. A kurtosis of $3$ is considered average, and represents a normal distribution. High kurtosis indicates a higher probability of extreme movements. A distribution with kurtosis lower than $3$ is called **platykurtic**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"multivariate_distribution_functions\">Multivariate Distribution Functions</a>\n",
    "In practice, portfolio payoffs depend on numerous random variables. \n",
    "### Joint distributions\n",
    "We can extend univariate distribution function to \n",
    "\n",
    "$F_{12}(x_{1}, x_{2}) = P(X_{1} \\leq x_{1}, X_{2} \\leq x_{2}) $\n",
    "\n",
    "which defines a joint bivariate distributiion function. In the continuous case, this is also\n",
    "\n",
    "$F_{12}(x_{1}, x_{2}) = \\int^{x_{1}}_{-\\infty}\\int^{x_{2}}_{-\\infty}f_{12}(u_{1}, u_{2})du_{1}du_{2}$\n",
    "\n",
    "where $f(u_{1}, u_{2})$ is now the **joint density**.\n",
    "\n",
    "The analysis simplifies considerably if the variables are **independent**. In this case, the joint density separates out into the product of the densities:\n",
    "\n",
    "$f_{12}(u_{1}, u_{2}) = f_{1}(u_{1}) \\times f_{2}(u_{2})$\n",
    "\n",
    "and the integral reduces to \n",
    "\n",
    "$F_{12}(x_{1}, x_{2}) = F_{1}(x_{1}) \\times F_{2}(x_{2})\n",
    "\n",
    "It's also useful to characterize the distribution of x_{1} abstracting from x_{2}. By integrating over all values of x_{2}, we obtain the **marginal density**:\n",
    "\n",
    "$f_{1}(x_{1}) = \\int^{\\infty}_{-\\infty}f_{12}(x_{1}, u_{2})du_{2}$\n",
    "\n",
    "and similarly for $x_{2}$. We can then define the **conditional density** as \n",
    "\n",
    "$f_{1 \\cdot 2}(x_{1} | x_{2}) = \\frac{f_{12}(x_{1}, x_{2})}{f_{2}(x_{2})}$\n",
    "\n",
    "Here we keep $x_{2}$ fixed and divide the joint density by the marginal probability of $x_{2}$. This normalization is necessary to ensure that the conditional density is a proper density function that integrates to one. This relationship is also known as **Bayes' rule**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariances and correlations\n",
    "When dealing with two random variables, the comovement can be described by the **covariance**:\n",
    "\n",
    "$Cov(X_{1}, X_{2}) = \\sigma_{12} = \\int_{1}\\int_{2}[x_{1} - E(X_{1})][x_{2} - E(X_{2})]f_{12}(x_{1}, x_{2})dx_{1}dx_{2}$\n",
    "\n",
    "It's often useful to scale the covariance into a unitless number, called the **correlation coefficient**, obtained as \n",
    "\n",
    "$\\rho(X_{1}, X_{2}) = \\frac{Cov(X_{1}, X_{2})}{\\sigma_{1}\\sigma_{2}}$\n",
    "\n",
    "The correlation coefficient is a measure of linear dependence. The correlation coefficient always lies in the $[-1, +1]$ interval. A correlation of $1$ means that the two variables always move in the same direction. A correlation of $-1$ means that the two variables always move in the opposite direction.\n",
    "\n",
    "The above-mentioned equation is also called **Pearson correlation**. Another measure is the **Spearman correlation**, which replaces the value of the variables by their rank. This nonparametric measure is less sensitive to outliers, and hence more robust than the usual correlation when there might be errors in the data.\n",
    "\n",
    "If the variables are independent, the two variables are said to be **uncorrelated**. Independence implies $0$ correlation (the reverse is not true, however)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"functions_of_random_variables\">Functions of Random Variables</a>\n",
    "Risk management is about uncovering the distribution of portfolio values. Consider a security that depends on a unique source of risk, such as bond. The risk manager could model the change in the bond price as a random variable ($RV$) directly. The problem with this choice is that the distribution of the bond price is not stationary, because the price converges to the face value at expiration.\n",
    "\n",
    "Instead, the practice is to model the change in yields as a random variable because its distribution is better behaved. The next step is to use the relationship between the bond price and the yield to uncover the distribution of the bond price.\n",
    "\n",
    "This illustrates a general principle of risk management, which is to model the risk factor first, then to derive the distribution of the instrument from information about the function that links the instrument value to the risk factor.\n",
    "### Linear transformation of random variables\n",
    "Consider a transformation that multiplies the original random variable by a constant and add a fixed amount, $Y = a + bX$. The expectation of $Y$ is \n",
    "\n",
    "$E(a + bX) = a + bE(X)$\n",
    "\n",
    "and its variance is \n",
    "\n",
    "$V(a + bX) = b^{2}V(X)$\n",
    "\n",
    "Note that adding a constant never affects the variance since the computation involves the difference between the variable and its mean. The standard deviation is \n",
    "\n",
    "$SD(a + bX) = bSD(X)$\n",
    "### Sum of random variables\n",
    "The expectation of the sum $Y = X_{1} + X_{2}$ can be written as \n",
    "\n",
    "$E(X_{1} + X_{2}) = E(X_{1}) + E(X_{2})$\n",
    "\n",
    "and its variance is \n",
    "\n",
    "$V(X_{1} + X_{2}) = V(X_{1}) + V(X_{2}) + 2Cov(X_{1}, X_{2})$\n",
    "\n",
    "When the variables are uncorrelated, the variance of the sum reduces to the sum of variances. Otherwise, we have to account for the cross-product term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolios of random variables\n",
    "More generally, consider a linear combination of a number of random variables. This could be a portfolio with fixed weights, for which the rate of return is \n",
    "\n",
    "$Y = \\Sigma^{N}_{i=1}w_{i}X_{i}$\n",
    "\n",
    "where $N$ is the number of assets, $X_{i}$ is the rate of return on asset $i$, and $w_{i}$ its weight.\n",
    "\n",
    "In matrix notation:\n",
    "\n",
    "$Y = w_{1}X_{1} + ... + w_{N}X_{N} = \\begin{bmatrix} w_{1}&w_{2}&\\dots &w_{N} \\end{bmatrix} \\begin{bmatrix} X_{1} \\\\ X_{2} \\\\ \\vdots \\\\ X_{N} \\end{bmatrix} = w'X$\n",
    "\n",
    "The portfolio expected return is now \n",
    "\n",
    "$E(Y) = \\mu_{p} = \\Sigma^{N}_{i=1}w_{i}\\mu_{i}$\n",
    "\n",
    "which is a weighted average of the expected returns $\\mu_{i} = E(X_{i})$. The variance is \n",
    "\n",
    "$V(Y) = \\sigma^{2}_{p} = \\Sigma^{N}_{i=1}w^{2}_{i}\\sigma^{2}_{i} +\\Sigma^{N}_{i=1}\\Sigma^{N}_{j=1,j\\neq i}w_{i}w_{j}\\sigma_{ij} = \\Sigma^{N}_{i=1}w^{2}_{i}\\sigma^{2}_{i} + 2\\Sigma^{N}_{i=1}\\Sigma^{N}_{j<i}w_{i}w_{j}\\sigma_{ij}$\n",
    "\n",
    "Using matrix notation:\n",
    "\n",
    "$\\sigma^{2}_{p} = \\begin{bmatrix} w_{1}&\\dots&w_{N} \\end{bmatrix} \\begin{bmatrix} \\sigma_{11}&\\sigma_{12}&\\sigma_{13}&\\dots&\\sigma_{1N} \\\\ \\vdots & & & & \\vdots \\\\ \\sigma_{N1}&\\sigma_{N2}&\\sigma_{N3}&\\dots&\\sigma_{NN} \\end{bmatrix} \\begin{bmatrix} w_{1} \\\\ \\vdots \\\\ w_{N} \\end{bmatrix} = w'\\Sigma w$\n",
    "\n",
    "Define $\\Sigma$ as the covariance matrix. This is a useful expression to describe the risk of the total portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product of random variables\n",
    "The expectation of the product $Y = X_{1}X_{2}$ can ve written as\n",
    "\n",
    "$E(X_{1} X_{2}) = E(X_{1})E(X_{2}) + Cov(X_{1}, X_{2})$\n",
    "\n",
    "When the variables are independent, this reduces to the product of the means. \n",
    "\n",
    "The variance is more complex to evaluate. With independence, it reduces to:\n",
    "\n",
    "$V(X_{1} X_{2}) = E(X_{1})^{2}V(X_{2}) + V(X_{1})E(X_{2})^{2} + V(X_{1})V(X_{2})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of transformations of random variables\n",
    "The distribution of the transformed variable $Y = g(X)$ is usually complicated for all but the simplest transformations $g(\\cdot)$ and densities $f(X)$. Even if there is no closed-form solution for the density, we can describe the cumulative distribution function of $Y$ when $g(X)$ is a one-to-one transformation from $X$ into $Y$. This implies that the function can be inverted, or that for a given $y$, we can find $x$ such that $x = g^{-1}(y)$. We can then write\n",
    "\n",
    "$P[Y \\leq y] = P[g(X) \\leq y] = P[X \\leq g^{-1}(y)] = F_{x}(g^{-1}(y))$\n",
    "\n",
    "where $F(\\cdot)$ is the cumulative distributive function of $X$. Here, we assumed the relationship is positive. Otherwise, the right-hand term is changed to $1 - F_{x}(g^{-1}(y))$.\n",
    "\n",
    "This allows us to derive the quantile of the bond price from information about the probability distribution of the yield. Suppose we consider a zero-coupon bond, for which the market value $V$ is \n",
    "\n",
    "$V = \\frac{100}{(1 + r)^{T}}$\n",
    "\n",
    "where $r$ is the yield. \n",
    "\n",
    "$r = (100/V)^{1/T} - 1$\n",
    "\n",
    "Unfortunately, this method cannot be easily extended. For general density functions and transformations, risk managers turn to numerical methods, especially when the number of random variables is large. This is why credit risk models all describe the distribution of credit losses through simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"important_distribution_functions\">Important Distribution Functions</a>\n",
    "### Uniform distribution\n",
    "$f(x) = \\frac{1}{b - a}$, $a \\leq x \\leq b$\n",
    "\n",
    "This density function is constant and indeed integrates to unity. This distribution puts the same weight on each observation within the allowable range. We denote this distribution as $U(a, b)$. It's mean and variance are given by\n",
    "\n",
    "$E(X) = \\frac{a + b}{2}$\n",
    "\n",
    "$V(X) = \\frac{(b - a)^{2}}{12}$\n",
    "\n",
    "The uniform distribution $U(0, 1)$ is widely used as a starting distribution for generating random variables from any distribution $F(Y)$ in simulations. We need to have analytical formulas for the $p.d.f$ $f(Y)$ and its sumulative distribution $F(Y)$. As any cumulative distribution function ranges from zero to unity, we first draw $X$ from $U(0, 1)$ and then compute $y = F^{-1}(x)$. The random variable will then have the desired distribution $f(Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distribution\n",
    "The daily rate of return in a stock price has a distribution similar to the normal $p.d.f$. The normal distribution can be characterized by its first two moments only, the mean $\\mu$ and variance $\\sigma^{2}$. The first parameter represents the location; the second, the dispersion. \n",
    "\n",
    "$f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^{2}}} exp[-\\frac{1}{2\\sigma^{2}}(x - \\mu)^{2}]$\n",
    "\n",
    "Its mean is $E[X] = \\mu$ and variance $V[X] = \\sigma^{2}$. We denote this distribution as $N(\\mu, \\sigma^2)$. Because the function can be fully specified by these two parameters, it's called a **parametric function**.\n",
    "\n",
    "Instead of having to deal with different parameters, it's often more convenient to use a **standard normal variable** as $\\epsilon$, which has been standardized, or normalized, so that $E(\\epsilon) = 0, V(\\epsilon) = \\sigma(\\epsilon) = 1$.\n",
    "\n",
    "First, note that the function is symmetrical around the mean. Its mean of zero is the same as its **mode** (which is also the most likely, or highest, point on this curve) and **median** (which is such that the area to the left is a $50\\%$ probability). The skewness of a normal distribution is $0$, which indicates that it is symmetrical around the mean. The kurtosis of a normal distribution is $3$. Distributions with fatter tails have a greater kurtosis coefficient.\n",
    "\n",
    "$\\int^{\\infty}_{-\\alpha}f(\\epsilon)d\\epsilon = c$\n",
    "\n",
    "For example, $-\\alpha = -1.645$ is the quantile that corresponds to a $95\\%$ probability (confidence level).\n",
    "\n",
    "This distribution plays a central role in finance because it represents adequately the behavior of many financial variables. For instance, it enters the Black-Scholes option pricing formula where the function $N(\\cdot)$ represents the cumulative standardized normal distribution function.\n",
    "\n",
    "The distribution of any normal variable can then be recovered from that of the standard normal, by defining\n",
    "\n",
    "$X = \\mu + \\epsilon\\sigma$\n",
    "\n",
    "We can show that $X$ has indeed the desired moments, as $E(X) = \\mu + E(\\epsilon)\\sigma = \\mu$ and $V(X) = V(\\epsilon)\\sigma^{2} = \\sigma^{2}$.\n",
    "\n",
    "Define the random variable as the change in the dollar value of a portfolio. The expected value is $E(X) = \\mu$. To find the quantile of $X$ at the specified confidence level $c$, we replace $\\epsilon$ by $-\\alpha$. This gives $Q(X, c) = \\mu - \\alpha\\sigma$. We then can compute $VAR$ as\n",
    "\n",
    "$VAR = E(X) - Q(X, c) = \\mu - (\\mu - \\alpha\\sigma) = \\alpha\\sigma$\n",
    "\n",
    "The normal distribution is one of the few distributions that is stable under addition. In other words, a linear combination of joint normally distribured random variables has a normal distribution. This is extremely useful because we need to know only the mean and variance of the portfoliio to reconstruct its whole distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lognormal distribution\n",
    "The normal distribution is a good approximation for many financial variables, such as the rate of return on a stock, $r = (P_{1} - P_{0})/P_{0}$, where $P_{0}$ and $P_{1}$ are the stock prices at time $0$ and $1$. \n",
    "\n",
    "Strictly speaking, this is inconsistent with reality since a normal variable has infinite tails on both sides. In theory, $r$ could end up below $-1$, which implies $P_{1} < 0$. In reality, due to the limited liability of corporations, stock prices cannot turn negative. Hence we need to resort to other distributions that prevent prices from going negative. One such distribution is the lognormal.\n",
    "\n",
    "A random variable $X$ is said to have a **lognormal distribution** if its logarithm $Y = ln(X)$ is normally distributed. Define here $X = (P_{1}/P_{0})$. Because the argument $X$ in the logarithm function must be positive, the price $P_{1}$ can never go below $0$. The lognormal density function has the following expression:\n",
    "\n",
    "$f(x) = \\frac{1}{x\\sqrt{2\\pi\\sigma^{2}}}exp[-\\frac{1}{2\\sigma^{2}}(ln(x) - \\mu)^{2}], x > 0$\n",
    "\n",
    "Its mean is \n",
    "\n",
    "$E[X] = exp[\\mu + \\frac{1}{2}\\sigma^{2}]$\n",
    "\n",
    "and variance $V[X] = exp[2\\mu + 2\\sigma^{2}] - exp[2\\mu + \\sigma^{2}]$. The parameters were chosen to correspond to those of the normal variable, $E[Y] = E[ln(X)] = \\mu$ and $V[Y] = V[ln(X)] = \\sigma^{2}$.\n",
    "\n",
    "Conversely, if we set $E[X] = exp[r]$, the mean of the associated normal variable is $E[Y] = E[ln(X)] = (r - \\sigma^{2}/2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student's t distribution\n",
    "This distribution is characterized by a parameter $k$ known as the **degrees of freedom**. Its density\n",
    "\n",
    "$f(x) = \\frac{\\Gamma[(k + 1)/2]}{\\Gamma(k/2)}\\frac{1}{\\sqrt{k\\pi}}\\frac{1}{(1 + x^{2} / k)^{(k + 1)/2}}$\n",
    "\n",
    "where $\\Gamma$ is the gamma function, defined as $\\Gamma(k) = \\int^{\\infty}_{0}x^{k-1}e^{-x}dx$. As $k$ increases, this function converges to the normal $p.d.f$.\n",
    "\n",
    "The distribution is symmetrical with $0$ and variance\n",
    "\n",
    "$V[X] = \\frac{k}{k - 2}$\n",
    "\n",
    "provided $k > 2$. Its kurtosis is \n",
    "\n",
    "$\\delta = 3 + \\frac{6}{k - 4}$\n",
    "\n",
    "provided $k > 4$. It has fatter tails than the normal distribution, which often provides a better representation of typical financial variables. Typical estimated values of $k$ are around $4$ to $6$ for stock returns.\n",
    "\n",
    "$VAR = \\alpha_{k}\\sigma$\n",
    "\n",
    "where the multiplier now depends on the degrees of freedom $k$.\n",
    "\n",
    "Another distribution derived from the normal is the **chi-square distribution**, which can be viewed as the sum of independent squared standard normal variables \n",
    "\n",
    "$x = \\Sigma^{k}_{j=1}z^{2}_{j}$\n",
    "\n",
    "where $k$ is also called the degrees of freedom. Its mean is $E[X] = k$ and variance $V[X] = 2k$. For values of $k$ sufficiently large, $\\chi^{2}(k)$ converges to a normal distribution $N(k, 2k)$. This distribution describes the sample variance.\n",
    "\n",
    "Another associated distribution is the **F distribution**, which can be viewed as the ratio of independent chi-square variables divided by their degrees of freedom\n",
    "\n",
    "$F(a, b) = \\frac{\\chi^{2}(a)/a}{\\chi^{2}(b)/b}$\n",
    "\n",
    "This distribution appears in joint tests of regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Binomial distribution\n",
    "Consider a random variable that can take discrete values between $0$ and $n$. This could be, for instance, the number of times $VAR$ is exceeded over the last year, also called the number of **exceptions**. Thus, the binomial distribution plays an important role for the backtesting of $VAR$ models.\n",
    "\n",
    "A binomial variable can be viewed as the result of $n$ independent **Bernoulli trials**, where each trial results in an outcome of $y = 0$ or $y = 1$. This applies to credit risk. In case of default, we have $y = 1$, otherwise $y = 0$. Each Bernoulli variable has expected value of $E[Y] = p$ and variance $V[Y] = p(1 - p)$.\n",
    "\n",
    "A random variable is defined to have a **binomial distribution** if the discrete density function is given by\n",
    "\n",
    "$f(x) = \\begin{pmatrix}n\\\\x\\end{pmatrix}p^{x}(1 - p)^{n-x}, x = 0, 1, ..., n$\n",
    "\n",
    "where $\\begin{pmatrix}n\\\\x\\end{pmatrix}$ is the number of combinations of $n$ things taken $x$ at a time, or \n",
    "\n",
    "$\\begin{pmatrix}n\\\\x\\end{pmatrix} = \\frac{n!}{x!(n - x)!}$\n",
    "\n",
    "and the parameter $p$ is between $0$ and $1$. This distribution also represents the total number of successes in $n$ repeated experiments where each success has a probability of $p$.\n",
    "\n",
    "The binomial variable has mean and variance \n",
    "\n",
    "$E[X] = pn$\n",
    "\n",
    "$V[X] = p(1 - p)n$\n",
    "\n",
    "A related distribution is the **negative binomial distribution**. Instead of a fixed number of trials, this involves repeating the experiment until a fixed number of failures $r$ has occurred. The density is \n",
    "\n",
    "$f(x) = \\begin{pmatrix}x + r - 1\\\\r - 1\\end{pmatrix}p^{x}(1 - p)^{r}, x =0, 1, ...$\n",
    "\n",
    "In other words, this is the distribution of the number of successes before the $r$th failure of a Bernoulli process. Its mean is $E[X] = r\\frac{p}{1 - p}$. Also note that $x$ does not have an upper limit, unlike the variable in the usual binomial density."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson distribution\n",
    "The Poisson distribution is a discrete distribution, which typically is used to describe the number of events occurring over a fixed period of time, assuming events are independent of each other. It is defined as\n",
    "\n",
    "$f(x) = \\frac{e^{-\\lambda}\\lambda^{x}}{x!}, x = 0, 1,...$\n",
    "\n",
    "where $\\lambda$ is a positive number representing the average arrival rate durring the period. This distribution is widely used to represent the frequency, or number of occurrences, of operational losses over a year.\n",
    "\n",
    "The parameter $\\lambda$ represents the expected value of $X$ and also its variance \n",
    "\n",
    "$E[X] = \\lambda$\n",
    "\n",
    "$V[X] = \\lambda$\n",
    "\n",
    "The Poisson distribution is the limiting case of the binomial distribution, as $n$ goes to $\\infty$ and $p$ goes to $0$, while $np = \\lambda$ remains fixed. In addition, when $\\lambda$ is large the Poisson distribution is well approximated by the normal distribution with mean and variance of $\\lambda$, through the central limit theorem.\n",
    "\n",
    "If the number of arrivals follows a Poisson distribution, then the time period between arrivals follows an **exponential distribution** with mean $1/\\lambda$. The latter has density taking the form $f(x) = \\lambda e^{-\\lambda x}$, for $x \\geq 0$. For example, if we expect $\\lambda = 12$ losses per year, the average time interval between losses should be one year divided by $12$, or one month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"distribution_of_averages\">Distribution of Averages</a>\n",
    "The normal distribution is extremely important because of the **central limit theorem (CLT)**, which states that the mean of $n$ independent and identically distributed ($i.i.d.$) variables converges to a normal distribution as the number of observations $n$ increases. This very powerful result is valid for any underlying distribution, as long as the realizations are independent. For instance, the distribution of total credit losses converges to a normal distribution as the number of loans increases to a large value, assuming defaults are always independent of each other.\n",
    "\n",
    "Define $\\bar{X}$ as the mean $\\frac{1}{n}\\Sigma^{n}_{i=1}X_{i}$, where each variable has mean $\\mu$ and standard deviation $\\sigma$. We have\n",
    "\n",
    "$\\bar{X}\\rightarrow N(\\mu, \\frac{\\sigma^{2}}{n}) $\n",
    "\n",
    "Standardizing the variable, we can write\n",
    "\n",
    "$\\frac{\\bar{X} - \\mu}{\\sigma/\\sqrt{n}} \\rightarrow N(0, 1)$\n",
    "\n",
    "Thus, the normal distribution is the limiting distribution of the average, which explains why it has such a prominent place in statistics.\n",
    "\n",
    "As an example, consider the binomial variable, which is the sum of independent Bernoulli trials. When $n$ is large, we can use the $CLT$ and approximate the binomial distribution by the normal distribution. \n",
    "\n",
    "$z = \\frac{x - pn}{\\sqrt{p(1 - p)n}} \\rightarrow N(0, 1)$\n",
    "\n",
    "which is much easier to evaluate than the binomial distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
