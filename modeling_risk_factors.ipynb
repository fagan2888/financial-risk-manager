{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Risk Factors\n",
    "We are going to analyze the distribution of risk factors used in financial risk management. A common practice is to use the volatility as a single measure of dispersion. More generally, risk managers need to consider the entire shape of the distribution as well as potential variation in time of this distribution.\n",
    "\n",
    "The normal distribution is a useful starting point due to its attractive properties. Unfortunately, most financial time series are characterized by fatter tails than the normal distribution. In addition, there is ample empirical evidence that risk changes in a predictable fashion. This phenomenon, called **volatility clustering**, could also explain the appearance of fat tails. Extreme observations could be drawn from periods with high volatility. This could cause the appearance of fat tails when combining periods of low and high volatility.\n",
    "\n",
    "* [Real Data](#real-data)\n",
    "* [Normal and Lognormal Distributions](#normal-and-lognormal-distributions)\n",
    "* [Distributions with Fat Tails](#distributions-with-fat-tails)\n",
    "* [Time Variation in Risk](#time-variation-in-risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"real-data\">Real Data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Returns\n",
    "We observe movements in the daily yen/dollar exchange rate and wish to characterize the distribution of tomorrow's exchange rate. The risk manager's job is to assess the range of potential gains and losses on a trader's position. There is a sequence of past prices $P_{0}, P_{1}, ...,P_{t}$, from which the distribution of tomorrow's price, $P_{t+1}$, should be inferred.\n",
    "\n",
    "The truly random component in tomorrow's price is not its level, but rather its change relative to today's price. We measure the relative rate of change in the spot price:\n",
    "\n",
    "$r_{t} = (P_{t} - P_{t-1})/P_{t-1}$\n",
    "\n",
    "Alternately, we could construct the logarithm of the price ratio:\n",
    "\n",
    "$R_{t} = ln[P_{t}/P_{t-1}]$\n",
    "\n",
    "which is equivalent to using continuous instead of discrete compounding. This is also \n",
    "\n",
    "$R_{t} = ln[1 + (P_{t} - P_{t-1})/P_{t-1}] = ln[1 + r_{t}]$\n",
    "\n",
    "Because $ln(1 + x)$ is close to $x$ if $x$ is small, $R_{t}$ should be close to $r_{t}$ provided the return is small. For daily data, there is typically little difference between $R_{t}$ and $r_{t}$.\n",
    "\n",
    "The next question is whether the sequence of variables $r_{t}$ can be viewed as independent observations. Independent observations have the very nice property that their joint distribution is the product of their marginal distribution, which considerably simplifies the analysis. The obvious question is whether this assumption is a workable approximation. In fact, there are good economic reasons to believe that rates of change on financial prices are close to independent.\n",
    "\n",
    "The hypothesis of **efficient markets** postulates that current prices convey all relevant information about the asset. If so, any change in the asset price must be due to news, or events that are by definition impossible to forecast (otherwise, the event would not be news). This implies that changes in prices are unpredictable and, hence, satisfy our definition of independent random variables.\n",
    "\n",
    "This hypothesis, also known as **random walk** theory, implies that the conditional distribution of returns depends on only current prices, and not on the previous history of prices. If so, technical analysis must be a fruitless exercise. Technical analysts try to forecast price movements from past price patterns. If in addition the distribution of returns is constant over time, the variables are said to be **independent and identically distributed** (i.i.d.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Aggregation\n",
    "It is often necessary to translate parameters over a given horizon to another horizon. For example, we have data for faily returns, from which we compute a daily volatility that we want to extend to a monthly volatility. This is a **time aggregation** problem.\n",
    "\n",
    "Returns can be easily aggregated when we use the log of the price ratio, because the log of a product is the sum of the logs of the individual terms. Over two periods, for instance, the price movement can be described as the sum of the price movements over each day:\n",
    "\n",
    "$R_{t,2} = ln(P_{t}/P_{t-1}) + ln(P_{t-1}/P_{t-2}) = R_{t-1} + R_{t}$\n",
    "\n",
    "The expected return and variance are then $E(R_{t,2}) = E(R_{t-1}) + E(R_{t})$ and $V(R_{t,2}) = V(R_{t-1}) + V(R_{t}) + 2Cov(R_{t-1}, R_{t})$. Assuming returns are uncorrelated (i.e., that the covariance term is zero) and have identical distributions across days, we have $E(R_{t,2}) = 2E(R_{t})$ and $V(R_{t,2}) = 2V(R_{t})$.\n",
    "\n",
    "More generally, define $T$ as the number of steps. The multiple-period expected return and volatility are \n",
    "\n",
    "$\\mu_{T} = \\mu T$\n",
    "\n",
    "$\\sigma_{T} = \\sigma \\sqrt{T}$\n",
    "\n",
    "When successive returns are uncorrelated, the volatility increases as the horizon extends following the square root of time.\n",
    "\n",
    "Assume now that the distribution is stable under addition, which means that it stays the same whether over one period or over multiple periods. This is the case for the normal distribution. If so, we can use the same multiplier $\\alpha$ that corresponds to a selected confidence level for a one-period and T-period return. The multiple-period $VAR$ is \n",
    "\n",
    "$VAR_{T} = \\alpha(\\alpha \\sqrt{T})W = VAR_{1}\\sqrt{T}$\n",
    "\n",
    "In other words, extension to a multiple period follows a square root of time rule. In summary, the square root of time rule applies to parametric $VAR$ under the following conditions:\n",
    "* The distribution is the same at each period (i.e., there is no predictable time variation in expected return nor in risk).\n",
    "* Returns are uncorrelated across each period.\n",
    "* The distribution is the same for one- or T-period, or is stable under addition, such as the normal distribution.\n",
    "\n",
    "If returns are not independent, we may be able to characterize longer-term risks. For instance, when returns follow a first-order autoregressive process, \n",
    "\n",
    "$R_{t} = \\rho R_{t-1} + u_{t}$\n",
    "\n",
    "we can write the variance of two-day returns as \n",
    "\n",
    "$V[R_{t} + R_{t-1}] = \\sigma^{2} \\times 2[1 + \\rho]$\n",
    "\n",
    "In this case, \n",
    "\n",
    "$VAR_{2} = \\alpha(\\sigma \\sqrt{2(1 + \\rho)})W = [VAR_{1}\\sqrt{2}]\\sqrt{1 + \\rho}$\n",
    "\n",
    "Because we are considering correlations in the time series of the same variable, $\\rho$ is called the **autocorrelation coefficient**, or the **serial autocorrelation coefficient**. A positive value for $\\rho$ describes a situation where a movement in one direction is likely to be followed by another in the same direction. This implies that markets display **trends**, or **momentum**. In this case, the longer-term volatility increases faster than with the usual square root of time rule.\n",
    "\n",
    "A negative value for $\\rho$, by contrast, describes a situation where a movement in one direction is likely to be reversed later. This is an example of **mean reversion**. In this case, the longer-term volatility increases more slowly than with the usual square root of time rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portfolio Aggregation\n",
    "Let us now turn to aggregation of returns across assets. Consider, for example, an equity portfolio consisting of investments in $N$ shares, Define the number of each share held as $q_{i}$ with unit price $S_{i}$. The portfolio value at time $t$ is then\n",
    "\n",
    "$W_{t} = \\Sigma^{N}_{i=1}q_{i}S_{i,t}$\n",
    "\n",
    "We can write the weight assigned to asset $i$ as\n",
    "\n",
    "$w_{i,t} = \\frac{q_{i}S_{i,t}}{W_{t}}$\n",
    "\n",
    "which by construction sum to unity. Using weights, however, rules out situations with zero net investment, $W_{t} = 0$, such as some derivatives positions. But we could have positive and negative weights if short selling is allowed, or weights greater than one if the portfolio can be leveraged.\n",
    "\n",
    "The next period, the portfolio value is \n",
    "\n",
    "$W_{t+1} = \\sum^{N}_{i=1}q_{i}S_{i,t+1}$\n",
    "\n",
    "assuming that the unit price incorporates any income payment. The gross, or dollar, return is then\n",
    "\n",
    "$W_{t+1} - W_{t} = \\sum^{N}_{i=1}q_{i}(S_{i,t+1} - S_{i,t})$\n",
    "\n",
    "and the rate of return is\n",
    "\n",
    "$\\frac{W_{t+1}\\: - W_{t}}{W_{t}} = \\Sigma^{N}_{i=1} \\frac{q_{i}S_{i,t}}{W_{t}} \\frac{S_{i,t+1}\\; - S_{i,t}}{S_{i,t}} = \\Sigma^{N}_{i=1} w_{i,t} \\frac{S_{i,t+1}\\; - S_{i,t}}{S_{i,t}}$\n",
    "\n",
    "So, the portfolio rate of return is a linear combination of the asset returns\n",
    "\n",
    "$r_{p,t+1} = \\sum^{N}_{i=1}w_{i,t}r_{i,t+1}$\n",
    "\n",
    "The dollar return is then \n",
    "\n",
    "$W_{t+1} - W_{t} = [\\sum^{N}_{i=1}w_{i,t}r_{i,t+1}]W_{t}$\n",
    "\n",
    "and has a normal distribution if the individual returns are also normally distributed.\n",
    "\n",
    "Alternatively, we could express the individual positions in dollar terms,\n",
    "\n",
    "$x_{i,t} = w_{i,t} W_{t} = q_{i}S_{i,t}$\n",
    "\n",
    "The dollar return is also, using dollar amounts,\n",
    "\n",
    "$W_{t+1} - W_{t} = [\\sum^{N}_{i=1}x_{i,t}r_{i,t+1}]$\n",
    "\n",
    "The variance of the portfolio dollar return is \n",
    "\n",
    "$V[W_{t+1} - W_{t}] = x'\\sum x$\n",
    "\n",
    "Because the portfolio follows a normal distribution, it is fully characterized by its expected return and variance. The portfolio $VAR$ is then \n",
    "\n",
    "$VAR = \\alpha\\sqrt{x'\\sum x}$\n",
    "\n",
    "where $\\alpha$ depends on the confidence level and the selected density function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"\">Normal and Lognormal Distributions</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Distribution\n",
    "The normal, or Gaussian, distribution is usually the first choice when modeling asset returns. This distribution plays a special role in statistics, as it is easy to handle and is stable under addition, meaning that a combination of jointly normal variables is itself normal. It also provides the limiting distribution of the average of independent random variables (through the central limit theorem).\n",
    "\n",
    "Empirically, the normal distribution provides a rough, first-order approximation to the distribution of many random variables: rates of changes in currency prices, rates of changes in stock prices, rates of changes in bond prices, changes in yields, and rates of changes in commodity prices. All of these are characterized by many occurrences of small moves and fewer occurrences of large moves. This provides a rationale for a distribution with more weight in the center, such as the bell-shaped normal distribution. For many applications, this is a sufficient approximation. This may not be appropriate for measuring tail risk, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing Returns\n",
    "Given the random variable the new price $P_{1}$, the current price $P_{0}$, defining $r = (P_{1} - P_{0})/P_{0}$ as the rate of return in the price, we can start with the assumption that this random variable is drawn from a normal distribution,\n",
    "\n",
    "$r \\sim \\Phi(\\mu, \\sigma)$\n",
    "\n",
    "with some mean $\\mu$ and standard deviation $\\sigma$. Turning to prices, we have $P_{1} = P_{0}(1 + r)$ and \n",
    "\n",
    "$P_{1} \\sim P_{0} + \\Phi(P_{0}\\mu, P_{0}\\sigma)$\n",
    "\n",
    "For instance, starting from a stock price of $\\$100$, if $\\mu = 0\\%$ and $\\sigma = 15\\%$, we have $P_{1} \\sim \\$100 + \\Phi(\\$0, \\$15)$.\n",
    "\n",
    "However, in this case, the normal distribution cannot be even theoretically correct. Because of limited liability, stock prices cannot go below zero. Similarly, commodity prices and yields cannot turn negative. This is why another popular distribution is the **lognormal distribution**, which is such that\n",
    "\n",
    "$R = ln(P_{1}/P_{0}) \\sim \\Phi(\\mu, \\sigma)$\n",
    "\n",
    "By taking the logarithm, the price is given by $P_{1} = P_{0}exp(R)$, which precludes prices from turning negative, as the exponential function is always positive.\n",
    "\n",
    "Comparing the normal distribution with the lognormal distribution over a one-year horizon with $\\sigma = 15\\%$ annually. The distributions are very similar, except for the tails. The lognormal is skewed to the right.\n",
    "\n",
    "The difference between the two distributions is driven by the size of the volatility parameter over the horizon. Small values of this parameter imply that the distributions are virtually identical. This can happen either when the asset is not very risky, that is, when the annual volatility is small, or when the horizon is very short. In this situation, there is very little chance of prices turning negative. The limited liability constraint is not important.\n",
    "\n",
    "|    | Daily | Annual |\n",
    "|:---|:-----:|:------:|\n",
    "| Initial price | $100$ | $100$ |\n",
    "| Ending price | $101$ | $115$ |\n",
    "| Discrete return | $1.0000$ | $15.0000$ |\n",
    "| Log return | $0.9950$ | $13.9762$ |\n",
    "| Discrete return | $0.50\\%$ | $7.33\\%$ |\n",
    "\n",
    "The normal and lognormal distributions are very similar for short horizons or low volatilities.\n",
    "\n",
    "The above table compares the computation of returns over a one-day horizon and a one-year horizon. The one-day returns are $1.000\\%$ and $0.995\\%$ for discrete and log returns, respectively, which translates into a relative difference of $0.5\\%$, which is minor. In contrast, the difference is more significant over longer horizons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"distributions-with-fat-tails\">Distributions with Fat Tails</a>\n",
    "Perhaps the most serious problem with the normal distribution is the fact that its tails disappear too fast, at least faster than what is empirically observed in financial data. We typically observe that every market experiences one or more daily moves of four standard deviations or more per year. Such frequency is incompatible with a normal distribution. With a normal distribution, the probability of this happening is $0.0032\\%$ for one day, which implies a frequency of once every $125$ years. And in any year, there is usually at least one market that has a daily move greater than $10$ standard deviations.\n",
    "\n",
    "The empirical observation can be explained in a number of ways:\n",
    "1. The true distribution has fatter tails (e.g., the Student's $t$).\n",
    "2. The observations are drawn from a mix of distributions (e.g., a mix of two normals, one with low risk, the other with high risk).\n",
    "3. The distribution is nonstationary. \n",
    "\n",
    "he Student's $t$ density has fatter tails, which better reflect the occurrences of extreme observations in empirical financial data.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"time-variation-in-risk\">Time Variation in Risk</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fat tails can also occur when risk factors are drawn from a distribution with time-varying volatility. To be practical, this time variation must have some predictability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving Average\n",
    "Consider a traditional problem where a risk manager observes a sequence of $T$ returns $r_{t}$, from which the variance must be estimated. To simplify, ignore the mean return. At time $t$, the traditional variance estimate is \n",
    "\n",
    "$\\sigma_{t}^{2} = (1/T)\\sum^{T}_{i=1}r^{2}_{t-i}$\n",
    "\n",
    "This is a simple average where the weight on each past observation is $w_{i} = 1/T$. This may not be the best use of the data, however, especially if more recent observations are more relevant for the next day.\n",
    "\n",
    "If ploting daily returns on the S&P 500 index, we observe **clustering** in volatility after the Lehman bankruptcy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GARCH\n",
    "A practical model for volatility clustering is the **generalized autoregressive conditional heteroskedastic (GARCH)** model. This class of models assumes that the return at time $t$ has a particular distribution such as the normal, conditional on parameters $\\mu_{t}$ and $\\sigma_{t}$:\n",
    "\n",
    "$r_{t} \\sim \\Phi(\\mu_{t},\\sigma_{t})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
